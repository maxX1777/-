import requests
import string
import random
import json
from lxml import etree
import os
from io import BytesIO
import urllib.request




class BookSpider(object):
    def __init__(self):
        self.base_url = "http://www.allitebooks.org/page/{}"
        self.headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'}
        self.flag = 0
        self.data_list = []
    def get_url_list(self):
        url_list = []
        for i in range(1,3):
            url = self.base_url.format(i)
            url_list.append(url)
        return url_list
#发请求
    def send_request(self,url):
        data = requests.get(url, headers = self.headers).content.decode()
        return data

#解析数据
    def parse_xpath_data(self,data):
        parse_data = etree.HTML(data)
        #解析出所有的书的相关信息
        book_list = parse_data.xpath('//div[@class="main-content-inner clearfix"]/article')
        for book in book_list:
        #抓书名
            book_dict = {}
            book_dict['book_name'] = book.xpath('.//h2[@class="entry-title"]//text()')
            #print(book_name)
        # 图片url
            book_dict['bookimg_url'] = book.xpath('.//div[@class="entry-thumbnail hover-thumb"]/a/img/@src')
            #for url in bookimg_url:
                #url_sub = url
                #opener = urllib.request.build_opener()
                #opener.addheaders = [('User-agent',
                                      #'Opera/9.80 (Android 2.3.4; Linux; Opera Mobi/build-1107180945; U; en-GB) Presto/2.8.149 Version/11.10')]
                #urllib.request.install_opener(opener)
                #path = r'C:\Users\xycmj\.PyCharmCE2019.3\untitled2\pic' + str(self.flag) + '.jpg'
                #urllib.request.urlretrieve(url_sub, path)
                #self.flag = self.flag+1
                #print(index)
                #print(url)
                #print(self.flag)
        # 书简介
            book_dict['book_author'] = book.xpath('.//h5[@class="entry-author"]/a/text()')
            #print(book_author)
        # 作者
            book_dict['book_info'] = book.xpath('.//div[@class="entry-summary"]/p/text()')
            #print(book_info)
            self.data_list.append(book_dict)




        #print(book_list)
#保存数据
    def save_data(self,data):
        json.dump(self.data_list,open("04book.json",'w'))

    def run(self):
        url_list = self.get_url_list()
        for url in url_list:
            data = self.send_request(url)
            self.parse_xpath_data(data)
            self.save_data(data)

        print(self.data_list)


BookSpider().run()
